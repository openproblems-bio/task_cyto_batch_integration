def exitStrat(task, max_attempts = 3) {
  println "Determining exit strategy for task (attempt '${task.attempt}', exit status '${task.exitStatus}')"

  // if the component failed 3 times, ignore the error so the workflow can continue
  // it's important 'ignore' is returned even if maxRetries is set to 3,
  // otherwise the workflow will stop
  if (task.attempt >= 3) {
    return 'ignore'
  }
  
  return 'retry'
}

apptainer {
  enabled = true
  pullTimeout = '2h'
  ociAutoPull = true
  cacheDir = '/vast/scratch/users/putri.g/nextflow/apptainer_cache'
  libraryDir = '/vast/scratch/users/putri.g/nextflow/apptainer_library'
  runOptions = '-W /vast/scratch/users/putri.g/nextflow/apptainer_tmp'
  envWhitelist = 'APPTAINER_CACHEDIR,APPTAINER_TMPDIR,APPTAINER_LIBRARYDIR,SINGULARITY_CACHEDIR,SINGULARITY_TMPDIR,TMPDIR,NXF_HOME,NXF_TEMP,NXF_APPTAINER_CACHEDIR,PYTHONPATH'
}

env {
  SHARED_SCRATCH = '/vast/scratch/users/putri.g/nextflow'
  NXF_APPTAINER_CACHEDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_cache'
  APPTAINER_CACHEDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_cache'
  APPTAINER_TMPDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_tmp'
  APPTAINER_LIBRARYDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_library'
  SINGULARITY_CACHEDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_cache'
  SINGULARITY_TMPDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_tmp'
  TMPDIR = '/vast/scratch/users/putri.g/nextflow/apptainer_tmp'
  NXF_HOME = '/vast/scratch/users/putri.g/nextflow/nxf_home'
  NXF_TEMP = '/vast/scratch/users/putri.g/nextflow/nxf_tmp'
  PYTHONPATH = '/root/.local/lib/python3.12/site-packages'
}

process {
  beforeScript = '''
    mkdir -p "$APPTAINER_CACHEDIR" "$APPTAINER_TMPDIR" "$APPTAINER_LIBRARYDIR" "$NXF_HOME" "$NXF_TEMP" "$HOME"
    export TMPDIR="${TMPDIR}/${NXF_TASK_INDEX:-$$}"
    mkdir -p "$TMPDIR"
    echo "Task-specific TMPDIR: $TMPDIR"
    echo "APPTAINER_CACHEDIR=$APPTAINER_CACHEDIR"
    echo "NXF_APPTAINER_CACHEDIR=$NXF_APPTAINER_CACHEDIR"
    echo "NXF_HOME=$NXF_HOME"
    echo "NXF_TEMP=$NXF_TEMP"
  '''.stripIndent()
}


process {
  executor = 'slurm'

  // Default resources for all processes
  cpus = 4
  memory = { get_memory( 10.GB * task.attempt ) }
  time = '48.h'
  disk = 50.GB
  queue = 'regular'

  // Retry for exit codes that have something to do with memory issues
  // always retry once
  errorStrategy = { exitStrat(task) }
  maxRetries = 3
  maxMemory = null

  // Resource labels
  withLabel: lowcpu { cpus = 5 }
  withLabel: midcpu { cpus = 15 }
  withLabel: highcpu { cpus = 30 }
  withLabel: lowmem { memory = { get_memory( 10.GB * task.attempt ) } }
  withLabel: midmem { memory = { get_memory( 30.GB * task.attempt ) } }
  withLabel: highmem { memory = { get_memory( 80.GB * task.attempt ) } }
  withLabel: veryhighmem { memory = { get_memory( 150.GB * task.attempt ) } }
  withLabel: lowtime { time = 2.h }
  withLabel: midtime { time = 4.h } 
  withLabel: hightime { time = 12.h } 
  withLabel: veryhightime { time = 24.h } 
  withLabel: lowsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.05)}" : ""}
  }
  withLabel: midsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.1)}" : ""}
  }
  withLabel: highsharedmem {
    containerOptions = { workflow.containerEngine != 'singularity' ? "--shm-size ${String.format("%.0f",task.memory.mega * 0.25)}" : ""}
  }
  withLabel: gpu {
    cpus = 16
    clusterOptions = '--gres=gpu:A30:1'
    queue = "gpuq"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: midgpu {
    cpus = 32
    clusterOptions = '--gres=gpu:A30:4'
    queue = "gpuq"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: highgpu {
    cpus = 64
    clusterOptions = '--gres=gpu:A30:8'
    queue = "gpuq"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }
  withLabel: biggpu {
    cpus = 16
    clusterOptions = '--gres=gpu:A100:1'
    queue = "gpuq"
    containerOptions = { workflow.containerEngine == "singularity" ? '--nv':
       ( workflow.containerEngine == "docker" ? '--gpus all': null ) }
  }

  // make sure publishstates gets enough disk space and memory
  withName:'.*publishStatesProc' {
    memory = '16GB'
    disk = '100GB'
  }
}

def get_memory(to_compare) {
  if (!process.containsKey("maxMemory") || !process.maxMemory) {
    return to_compare
  }

  try {
    if (process.containsKey("maxRetries") && process.maxRetries && task.attempt == (process.maxRetries as int)) {
      return process.maxMemory
    }
    else if (to_compare.compareTo(process.maxMemory as nextflow.util.MemoryUnit) == 1) {
      return max_memory as nextflow.util.MemoryUnit
    }
    else {
      return to_compare
    }
  } catch (all) {
        println "Error processing memory resources. Please check that process.maxMemory '${process.maxMemory}' and process.maxRetries '${process.maxRetries}' are valid!"
        System.exit(1)
  }
}

// set tracing file
trace {
    enabled = true
    overwrite = true
    file = "${params.publish_dir}/trace.txt"
}
