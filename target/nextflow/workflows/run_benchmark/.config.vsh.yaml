name: "run_benchmark"
namespace: "workflows"
version: "build_main"
argument_groups:
- name: "Inputs"
  arguments:
  - type: "file"
    name: "--input_unintegrated_censored"
    label: "Unintegrated Censored"
    summary: "An unintegrated dataset with certain columns (cells metadata), such\
      \ as the donor information, hidden.\nThese columns are intentionally hidden\
      \ to prevent bias.\nThe batch correction algorithm should not have to rely on\
      \ these information \nto properly integrate different batches.\nThis dataset\
      \ is used as the input for the batch correction algorithm. \nThe cells therein\
      \ are identical to those in the unintegrated dataset. \n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/cyto_spleen_subset/unintegrated_censored.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--input_unintegrated"
    label: "Unintegrated"
    summary: "The complete unintegrated dataset, including all cells' metadata (columns)\
      \ from the \nunintegrated_censored dataset. \nThe cells in this dataset are\
      \ the same to those in the unintegrated_censored dataset.\n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "cell_type"
          description: "Cell type information"
          required: true
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "string"
          name: "donor"
          description: "Donor ID"
          required: true
        - type: "string"
          name: "group"
          description: "Biological group of the donor"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/cyto_spleen_subset/unintegrated.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--input_validation"
    label: "Validation"
    summary: "Hold-out dataset for validation."
    description: "Dataset containing cells from samples that were held out for evaluating\
      \ batch integration output. \nThe cells that are in this dataset belong to samples\
      \ which are not included in the unintegrated \nor unintegrated_censored datasets.\n\
      For example, if samples from donor A are present in batch 1 and 2, the sample\
      \ from batch 1\nmay be used as input for the batch correction algorithm (and\
      \ thus present in unintegrated\nand unintegrated_censored datasets). \nThe sample\
      \ from batch 2, may not be included as an input for the batch correction algorithm,\n\
      but is needed to validate whether whether the algorithm managed to correct the\
      \ batch effect\nin batch 2 towards batch 1.\nThis sample will then be included\
      \ in this dataset (but not in unintegrated\nand unintegrated_censored datasets).\
      \  \n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "cell_type"
          description: "Cell type information"
          required: true
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "string"
          name: "donor"
          description: "Donor ID"
          required: true
        - type: "string"
          name: "group"
          description: "Biological group of the donor"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/cyto_spleen_subset/validation.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
- name: "Outputs"
  arguments:
  - type: "file"
    name: "--output_scores"
    description: "A yaml file containing the scores of each of the methods"
    info: null
    default:
    - "score_uns.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_method_configs"
    info: null
    default:
    - "method_configs.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_metric_configs"
    info: null
    default:
    - "metric_configs.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_dataset_info"
    info: null
    default:
    - "dataset_uns.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_task_info"
    info: null
    default:
    - "task_info.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
- name: "Methods"
  arguments:
  - type: "string"
    name: "--method_ids"
    description: "A list of method ids to run. If not specified, all methods will\
      \ be run."
    info: null
    required: false
    direction: "input"
    multiple: true
    multiple_sep: ";"
resources:
- type: "nextflow_script"
  path: "main.nf"
  is_executable: true
  entrypoint: "run_wf"
- type: "file"
  path: "_viash.yaml"
info: null
status: "enabled"
dependencies:
- name: "h5ad/extract_uns_metadata"
  repository:
    type: "github"
    repo: "openproblems-bio/core"
    tag: "build/main"
    path: "viash/core"
- name: "control_methods/shuffle_integration"
  repository:
    type: "local"
- name: "control_methods/shuffle_integration_by_batch"
  repository:
    type: "local"
- name: "control_methods/shuffle_integration_by_cell_type"
  repository:
    type: "local"
- name: "control_methods/no_integration"
  repository:
    type: "local"
- name: "control_methods/perfect_integration"
  repository:
    type: "local"
- name: "methods/harmonypy"
  repository:
    type: "local"
- name: "methods/limma_remove_batch_effect"
  repository:
    type: "local"
- name: "methods/combat"
  repository:
    type: "local"
- name: "methods/cycombine_nocontrols"
  repository:
    type: "local"
- name: "methods/gaussnorm"
  repository:
    type: "local"
- name: "metrics/emd"
  repository:
    type: "local"
- name: "metrics/n_inconsistent_peaks"
  repository:
    type: "local"
- name: "metrics/average_batch_r2"
  repository:
    type: "local"
repositories:
- type: "github"
  name: "core"
  repo: "openproblems-bio/core"
  tag: "build/main"
  path: "viash/core"
license: "MIT"
links:
  repository: "https://github.com/openproblems-bio/task_cyto_batch_integration"
  docker_registry: "ghcr.io"
runners:
- type: "nextflow"
  id: "nextflow"
  directives:
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      lowmem: "memory = 20.Gb"
      midmem: "memory = 50.Gb"
      highmem: "memory = 100.Gb"
      lowcpu: "cpus = 5"
      midcpu: "cpus = 15"
      highcpu: "cpus = 30"
      lowtime: "time = 1.h"
      midtime: "time = 4.h"
      hightime: "time = 8.h"
      veryhightime: "time = 24.h"
  debug: false
  container: "docker"
build_info:
  config: "src/workflows/run_benchmark/config.vsh.yaml"
  runner: "nextflow"
  engine: "native"
  output: "target/nextflow/workflows/run_benchmark"
  executable: "target/nextflow/workflows/run_benchmark/main.nf"
  viash_version: "0.9.0"
  git_commit: "dc032fd595a66d4affb9b1f274dcbdbfa6c5f5a6"
  git_remote: "https://github.com/openproblems-bio/task_cyto_batch_integration"
  dependencies:
  - "target/dependencies/github/openproblems-bio/core/build/main/nextflow/h5ad/extract_uns_metadata"
  - "target/nextflow/control_methods/shuffle_integration"
  - "target/nextflow/control_methods/shuffle_integration_by_batch"
  - "target/nextflow/control_methods/shuffle_integration_by_cell_type"
  - "target/nextflow/control_methods/no_integration"
  - "target/nextflow/control_methods/perfect_integration"
  - "target/nextflow/methods/harmonypy"
  - "target/nextflow/methods/limma_remove_batch_effect"
  - "target/nextflow/methods/combat"
  - "target/nextflow/methods/cycombine_nocontrols"
  - "target/nextflow/methods/gaussnorm"
  - "target/nextflow/metrics/emd"
  - "target/nextflow/metrics/n_inconsistent_peaks"
  - "target/nextflow/metrics/average_batch_r2"
package_config:
  name: "task_cyto_batch_integration"
  version: "build_main"
  label: "Cyto Batch Integration"
  summary: "Benchmarking of batch integration algorithms for cytometry data."
  description: "Cytometry is a non-sequencing single cell profiling technique commonly\
    \ used in clinical studies. \nIt is very sensitive to batch effects, which can\
    \ lead to biases in the interpretation of the result. \nBatch integration algorithms\
    \ are often used to mitigate this effect.\n\nIn this project, we are building\
    \ a pipeline for reproducible and continuous benchmarking \nof batch integration\
    \ algorithms for cytometry data.\nAs input, methods require cleaned and normalised\
    \ (using arc-sinh or logicle transformation)\ndata with multiple batches, cell\
    \ type labels, and biological subjects, with paired samples\nfrom a subject profiled\
    \ across multiple batches.\nThe batch integrated output must be an integrated\
    \ marker by cell matrix stored in \nAnndata format.\nAll markers in the input\
    \ data must be returned, regardless of whether they were integrated or not.\n\
    This output is then evaluated using metrics that assess how well the batch effects\n\
    were removed and how much biological signals were preserved. \n"
  info:
    image: "The name of the image file to use for the component on the website."
    test_resources:
    - type: "s3"
      path: "s3://openproblems-data/resources_test/task_cyto_batch_integration/"
      dest: "resources_test/task_cyto_batch_integration"
  repositories:
  - type: "github"
    name: "core"
    repo: "openproblems-bio/core"
    tag: "build/main"
    path: "viash/core"
  viash_version: "0.9.0"
  source: "src"
  target: "target"
  config_mods:
  - ".runners[.type == \"nextflow\"].config.labels := { lowmem : \"memory = 20.Gb\"\
    , midmem : \"memory = 50.Gb\", highmem : \"memory = 100.Gb\", lowcpu : \"cpus\
    \ = 5\", midcpu : \"cpus = 15\", highcpu : \"cpus = 30\", lowtime : \"time = 1.h\"\
    , midtime : \"time = 4.h\", hightime : \"time = 8.h\", veryhightime : \"time =\
    \ 24.h\" }\n"
  authors:
  - name: "Luca Leomazzi"
    roles:
    - "author"
    - "maintainer"
    info:
      github: "LuLeom"
  - name: "Givanna Putri"
    roles:
    - "author"
    - "maintainer"
    info:
      github: "ghar1821"
      orcid: "0000-0002-7399-8014"
  - name: "Robrecht Cannoodt"
    roles:
    - "author"
    info:
      github: "rcannood"
      orcid: "0000-0003-3641-729X"
  - name: "Katrien Quintelier"
    roles:
    - "contributor"
    info:
      github: "KatrienQ"
  - name: "Sofie Van Gassen"
    roles:
    - "contributor"
    info:
      github: "SofieVG"
  keywords:
  - "single-cell"
  - "openproblems"
  - "benchmark"
  license: "MIT"
  organization: "openproblems-bio"
  links:
    repository: "https://github.com/openproblems-bio/task_cyto_batch_integration"
    docker_registry: "ghcr.io"
    issue_tracker: "https://github.com/openproblems-bio/task_cyto_batch_integration/issues"
