name: "run_benchmark"
namespace: "workflows"
version: "build_main"
argument_groups:
- name: "Inputs"
  arguments:
  - type: "file"
    name: "--input_unintegrated_censored"
    label: "Unintegrated Censored"
    summary: "An unintegrated dataset with certain columns (cells metadata), such\
      \ as the donor information, hidden.\nThese columns are intentionally hidden\
      \ to prevent bias.\nThe batch correction algorithm should not have to rely on\
      \ these information \nto properly integrate different batches.\nThis dataset\
      \ is used as the input for the batch correction algorithm. \nThe cells therein\
      \ are identical to those in the unintegrated dataset. \n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/starter_file/unintegrated_censored.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--input_unintegrated"
    label: "Unintegrated"
    summary: "The complete unintegrated dataset, including all cells' metadata (columns)\
      \ from the \nunintegrated_censored dataset. \nThe cells in this dataset are\
      \ the same to those in the unintegrated_censored dataset.\n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "cell_type"
          description: "Cell type information"
          required: true
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "string"
          name: "donor"
          description: "Donor ID"
          required: true
        - type: "string"
          name: "group"
          description: "Biological group of the donor"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/starter_file/unintegrated.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--input_validation"
    label: "Validation"
    summary: "Hold-out dataset for validation."
    description: "Dataset containing cells from samples that were held out for evaluating\
      \ batch integration output. \nThe cells that are in this dataset belong to samples\
      \ which are not included in the unintegrated \nor unintegrated_censored datasets.\n\
      For example, if samples from donor A are present in batch 1 and 2, the sample\
      \ from batch 1\nmay be used as input for the batch correction algorithm (and\
      \ thus present in unintegrated\nand unintegrated_censored datasets). \nThe sample\
      \ from batch 2, may not be included as an input for the batch correction algorithm,\n\
      but is needed to validate whether whether the algorithm managed to correct the\
      \ batch effect\nin batch 2 towards batch 1.\nThis sample will then be included\
      \ in this dataset (but not in unintegrated\nand unintegrated_censored datasets).\
      \  \n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "cell_type"
          description: "Cell type information"
          required: true
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "string"
          name: "donor"
          description: "Donor ID"
          required: true
        - type: "string"
          name: "group"
          description: "Biological group of the donor"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n0: cannot be used as a control.\n>=\
            \ 1: can be used as a control.\nFor cells with >= 1: cells with the same\
            \ value come from the same donor.\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/starter_file/validation.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
- name: "Outputs"
  arguments:
  - type: "file"
    name: "--output_scores"
    description: "A yaml file containing the scores of each of the methods"
    info: null
    default:
    - "score_uns.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_method_configs"
    info: null
    default:
    - "method_configs.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_metric_configs"
    info: null
    default:
    - "metric_configs.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_dataset_info"
    info: null
    default:
    - "dataset_uns.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output_task_info"
    info: null
    default:
    - "task_info.yaml"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
- name: "Methods"
  arguments:
  - type: "string"
    name: "--method_ids"
    description: "A list of method ids to run. If not specified, all methods will\
      \ be run."
    info: null
    required: false
    direction: "input"
    multiple: true
    multiple_sep: ";"
resources:
- type: "nextflow_script"
  path: "main.nf"
  is_executable: true
  entrypoint: "run_wf"
- type: "file"
  path: "_viash.yaml"
info: null
status: "enabled"
dependencies:
- name: "h5ad/extract_uns_metadata"
  repository:
    type: "github"
    repo: "openproblems-bio/core"
    tag: "build/main"
    path: "viash/core"
- name: "control_methods/shuffle_integration"
  repository:
    type: "local"
- name: "control_methods/shuffle_integration_by_batch"
  repository:
    type: "local"
- name: "control_methods/shuffle_integration_by_cell_type"
  repository:
    type: "local"
- name: "methods/harmonypy"
  repository:
    type: "local"
- name: "methods/limma_remove_batch_effect"
  repository:
    type: "local"
- name: "metrics/emd"
  repository:
    type: "local"
repositories:
- type: "github"
  name: "core"
  repo: "openproblems-bio/core"
  tag: "build/main"
  path: "viash/core"
license: "MIT"
links:
  repository: "https://github.com/openproblems-bio/task_cyto_batch_integration"
  docker_registry: "ghcr.io"
runners:
- type: "nextflow"
  id: "nextflow"
  directives:
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      lowmem: "memory = 20.Gb"
      midmem: "memory = 50.Gb"
      highmem: "memory = 100.Gb"
      lowcpu: "cpus = 5"
      midcpu: "cpus = 15"
      highcpu: "cpus = 30"
      lowtime: "time = 1.h"
      midtime: "time = 4.h"
      hightime: "time = 8.h"
      veryhightime: "time = 24.h"
  debug: false
  container: "docker"
build_info:
  config: "src/workflows/run_benchmark/config.vsh.yaml"
  runner: "nextflow"
  engine: "native"
  output: "target/nextflow/workflows/run_benchmark"
  executable: "target/nextflow/workflows/run_benchmark/main.nf"
  viash_version: "0.9.0"
  git_commit: "dbbaf9431748201e86408b89d70cfc9d990f8676"
  git_remote: "https://github.com/openproblems-bio/task_cyto_batch_integration"
  dependencies:
  - "target/dependencies/github/openproblems-bio/core/build/main/nextflow/h5ad/extract_uns_metadata"
  - "target/nextflow/control_methods/shuffle_integration"
  - "target/nextflow/control_methods/shuffle_integration_by_batch"
  - "target/nextflow/control_methods/shuffle_integration_by_cell_type"
  - "target/nextflow/methods/harmonypy"
  - "target/nextflow/methods/limma_remove_batch_effect"
  - "target/nextflow/metrics/emd"
package_config:
  name: "task_cyto_batch_integration"
  version: "build_main"
  label: "Cyto Batch Integration"
  summary: "A one sentence summary of purpose and methodology. Used for creating an\
    \ overview tables."
  description: "Provide a clear and concise description of your task, detailing the\
    \ specific problem it aims\nto solve. Outline the input data types, the expected\
    \ output, and any assumptions or constraints.\nBe sure to explain any terminology\
    \ or concepts that are essential for understanding the task.\n\nExplain the motivation\
    \ behind your proposed task. Describe the biological or computational \nproblem\
    \ you aim to address and why it's important. Discuss the current state of research\
    \ in\nthis area and any gaps or challenges that your task could help address.\
    \ This section \nshould convince readers of the significance and relevance of\
    \ your task.\n"
  info:
    image: "The name of the image file to use for the component on the website."
    test_resources:
    - type: "s3"
      path: "s3://openproblems-data/resources_test/task_cyto_batch_integration/"
      dest: "resources_test/task_cyto_batch_integration"
  repositories:
  - type: "github"
    name: "core"
    repo: "openproblems-bio/core"
    tag: "build/main"
    path: "viash/core"
  viash_version: "0.9.0"
  source: "src"
  target: "target"
  config_mods:
  - ".runners[.type == \"nextflow\"].config.labels := { lowmem : \"memory = 20.Gb\"\
    , midmem : \"memory = 50.Gb\", highmem : \"memory = 100.Gb\", lowcpu : \"cpus\
    \ = 5\", midcpu : \"cpus = 15\", highcpu : \"cpus = 30\", lowtime : \"time = 1.h\"\
    , midtime : \"time = 4.h\", hightime : \"time = 8.h\", veryhightime : \"time =\
    \ 24.h\" }\n"
  authors:
  - name: "John Doe"
    roles:
    - "author"
    - "maintainer"
    info:
      github: "johndoe"
      orcid: "0000-0000-0000-0000"
      email: "john@doe.me"
      twitter: "johndoe"
      linkedin: "johndoe"
  keywords:
  - "single-cell"
  - "openproblems"
  - "benchmark"
  license: "MIT"
  organization: "openproblems-bio"
  links:
    repository: "https://github.com/openproblems-bio/task_cyto_batch_integration"
    docker_registry: "ghcr.io"
    issue_tracker: "https://github.com/openproblems-bio/task_cyto_batch_integration/issues"
