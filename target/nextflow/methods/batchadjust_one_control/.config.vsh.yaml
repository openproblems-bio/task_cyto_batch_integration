name: "batchadjust_one_control"
namespace: "methods"
version: "build_fix_failed_stuff"
argument_groups:
- name: "Parameters"
  arguments:
  - type: "integer"
    name: "--percentile"
    description: "scale channels to the Nth percentile of the reference batch"
    info:
      optimize:
        type: "linear"
        lower: 60
        upper: 99
    default:
    - 80
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ";"
- name: "Arguments"
  arguments:
  - type: "file"
    name: "--input"
    label: "Censored (split 1)"
    summary: "An unintegrated dataset with certain columns (cells metadata), such\
      \ as the donor information, hidden.\nThese columns are intentionally hidden\
      \ to prevent bias.\n"
    description: "An unintegrated dataset with certain columns (cells metadata), such\
      \ as the donor information, hidden.\nThese columns are intentionally hidden\
      \ to prevent bias.\nThe batch correction algorithm should not have to rely on\
      \ these information \nto properly integrate different batches.\nThis dataset\
      \ is used as the input for the batch correction algorithm. \nThe cells therein\
      \ are identical to those in the unintegrated dataset.\n"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "preprocessed"
          description: "preprocessed data, e.g. already compensated, transformed and\
            \ debris/doublets removed"
          required: true
        obs:
        - type: "string"
          name: "batch"
          description: "Batch information"
          required: true
        - type: "string"
          name: "sample"
          description: "Sample ID"
          required: true
        - type: "integer"
          name: "is_control"
          description: "Whether the sample the cell came from can be used as a control\
            \ for batch \neffect correction.\n\n* 0: cannot be used as a control.\n\
            * >= 1: can be used as a control.\n* For cells with >= 1: cells with the\
            \ same value come from the same donor.\n\nDifferent values indicate different\
            \ donors.\n"
          required: true
        var:
        - type: "integer"
          name: "numeric_id"
          description: "Numeric ID associated with each marker"
          required: true
        - type: "string"
          name: "channel"
          description: "The channel / detector of the instrument"
          required: true
        - type: "string"
          name: "marker"
          description: "The marker name associated with the channel"
          required: false
        - type: "string"
          name: "marker_type"
          description: "Whether the marker is a functional or lineage marker"
          required: true
        - type: "boolean"
          name: "to_correct"
          description: "Whether the marker will be batch corrected"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - name: "dataset_name"
          type: "string"
          description: "Nicely formatted name."
          required: true
        - type: "string"
          name: "dataset_url"
          description: "Link to the original source of the dataset."
          required: false
        - name: "dataset_reference"
          type: "string"
          description: "Bibtex reference of the paper in which the dataset was published."
          required: false
        - name: "dataset_summary"
          type: "string"
          description: "Short description of the dataset."
          required: true
        - name: "dataset_description"
          type: "string"
          description: "Long description of the dataset."
          required: true
        - name: "dataset_organism"
          type: "string"
          description: "The organism of the sample in the dataset."
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/mouse_spleen_flow_cytometry_subset/censored_split1.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "input"
    multiple: false
    multiple_sep: ";"
  - type: "file"
    name: "--output"
    label: "Integrated (split 1)"
    summary: "Integrated dataset which batch effect was corrected by an algorithm"
    info:
      format:
        type: "h5ad"
        layers:
        - type: "double"
          name: "integrated"
          description: "The integrated data as returned by a batch correction method"
          required: true
        uns:
        - type: "string"
          name: "dataset_id"
          description: "A unique identifier for the dataset"
          required: true
        - type: "string"
          name: "method_id"
          description: "A unique identifier for the method"
          required: true
        - type: "object"
          name: "parameters"
          description: "The parameters used for the integration"
          required: false
    example:
    - "resources_test/task_cyto_batch_integration/mouse_spleen_flow_cytometry_subset/integrated_split1.h5ad"
    must_exist: true
    create_parent: true
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ";"
resources:
- type: "r_script"
  path: "script.R"
  is_executable: true
- type: "file"
  path: "anndata_to_fcs.R"
- type: "file"
  path: "BatchAdjust.R"
- type: "file"
  path: "utils.R"
label: "Batchadjust with one control"
summary: "Batchadjust with all control sample."
description: "CytofBatchadjust corrects batch effects across cytometry data by aligning\
  \ signal intensity peaks for each channel across batches.\nThe algorithm uses technical\
  \ replicates included in each barcode set as reference points to anchor each batch.\
  \ \nAdjustments factors are calibrated using anchor samples representing each barcode\
  \ set, then applied to all samples composing a batch. \n\nThis implementation uses\
  \ samples only from one group as control samples.\n"
test_resources:
- type: "python_script"
  path: "run_and_check_output.py"
  is_executable: true
- type: "python_script"
  path: "check_config.py"
  is_executable: true
- type: "file"
  path: "resources_test/task_cyto_batch_integration/mouse_spleen_flow_cytometry_subset"
  dest: "resources_test/task_cyto_batch_integration/mouse_spleen_flow_cytometry_subset"
info:
  type: "method"
  type_info:
    label: "Method"
    summary: "A method for integrating batch effects in cytometry data."
    description: "A method for integrating batch effects in cytometry data.\n"
status: "enabled"
scope:
  image: "public"
  target: "public"
repositories:
- type: "github"
  name: "op"
  repo: "openproblems-bio/openproblems"
  tag: "build/main"
license: "MIT"
references:
  doi:
  - "10.3389/fimmu.2019.02367"
  bibtex:
  - "@article{schuyler2019minimizing,\n  title={Minimizing batch effects in mass cytometry\
    \ data},\n  author={Schuyler, Ronald P and Jackson, Conner and Garcia-Perez, Josselyn\
    \ E and Baxter, Ryan M and Ogolla, Sidney and Rochford, Rosemary and Ghosh, Debashis\
    \ and Rudra, Pratyaydipta and Hsieh, Elena WY},\n  journal={Frontiers in immunology},\n\
    \  volume={10},\n  pages={2367},\n  year={2019},\n  publisher={Frontiers Media\
    \ SA}\n}\n"
links:
  repository: "https://github.com/CUHIMSR/CytofBatchAdjust"
  docker_registry: "ghcr.io"
  documentation: "https://github.com/CUHIMSR/CytofBatchAdjust"
runners:
- type: "executable"
  id: "executable"
  docker_setup_strategy: "ifneedbepullelsecachedbuild"
- type: "nextflow"
  id: "nextflow"
  directives:
    label:
    - "midtime"
    - "midmem"
    - "midcpu"
    tag: "$id"
  auto:
    simplifyInput: true
    simplifyOutput: false
    transcript: false
    publish: false
  config:
    labels:
      lowmem: "memory = 20.Gb"
      midmem: "memory = 50.Gb"
      highmem: "memory = 100.Gb"
      lowcpu: "cpus = 5"
      midcpu: "cpus = 15"
      highcpu: "cpus = 30"
      lowtime: "time = 1.h"
      midtime: "time = 4.h"
      hightime: "time = 8.h"
      veryhightime: "time = 24.h"
  debug: false
  container: "docker"
engines:
- type: "docker"
  id: "docker"
  image: "openproblems/base_r:1"
  namespace_separator: "/"
  setup:
  - type: "r"
    packages:
    - "docstring"
    bioc:
    - "flowCore"
    bioc_force_install: false
    warnings_as_errors: true
  entrypoint: []
  cmd: null
build_info:
  config: "src/methods/batchadjust_one_control/config.vsh.yaml"
  runner: "nextflow"
  engine: "docker"
  output: "target/nextflow/methods/batchadjust_one_control"
  executable: "target/nextflow/methods/batchadjust_one_control/main.nf"
  viash_version: "0.9.4"
  git_commit: "6d5550f51203ee20a1a97245893df1f936219d85"
  git_remote: "https://github.com/openproblems-bio/task_cyto_batch_integration"
package_config:
  name: "task_cyto_batch_integration"
  version: "build_fix_failed_stuff"
  label: "Cyto Batch Integration"
  summary: "Benchmarking of batch integration algorithms for cytometry data."
  description: "Cytometry is a non-sequencing single cell profiling technique commonly\
    \ used in clinical studies. \nIt is very sensitive to batch effects, which can\
    \ lead to biases in the interpretation of the result. \nBatch integration algorithms\
    \ are often used to mitigate this effect.\n\nIn this project, we are building\
    \ a pipeline for reproducible and continuous benchmarking \nof batch integration\
    \ algorithms for cytometry data.\nAs input, methods require cleaned and normalised\
    \ (using arc-sinh or logicle transformation)\ndata with multiple batches, cell\
    \ type labels, and biological subjects, with paired samples\nfrom a subject profiled\
    \ across multiple batches.\nThe batch integrated output must be an integrated\
    \ marker by cell matrix stored in \nAnndata format.\nAll markers in the input\
    \ data must be returned, regardless of whether they were integrated or not.\n\
    This output is then evaluated using metrics that assess how well the batch effects\n\
    were removed and how much biological signals were preserved. \n"
  info:
    image: "The name of the image file to use for the component on the website."
    test_resources:
    - type: "s3"
      path: "s3://openproblems-data/resources_test/task_cyto_batch_integration/"
      dest: "resources_test/task_cyto_batch_integration"
  repositories:
  - type: "github"
    name: "op"
    repo: "openproblems-bio/openproblems"
    tag: "build/main"
  viash_version: "0.9.4"
  source: "src"
  target: "target"
  config_mods:
  - ".runners[.type == \"nextflow\"].config.labels := { lowmem : \"memory = 20.Gb\"\
    , midmem : \"memory = 50.Gb\", highmem : \"memory = 100.Gb\", lowcpu : \"cpus\
    \ = 5\", midcpu : \"cpus = 15\", highcpu : \"cpus = 30\", lowtime : \"time = 1.h\"\
    , midtime : \"time = 4.h\", hightime : \"time = 8.h\", veryhightime : \"time =\
    \ 24.h\" }\n"
  authors:
  - name: "Luca Leomazzi"
    roles:
    - "author"
    - "maintainer"
    info:
      github: "LuLeom"
  - name: "Givanna Putri"
    roles:
    - "author"
    - "maintainer"
    info:
      github: "ghar1821"
      orcid: "0000-0002-7399-8014"
  - name: "Robrecht Cannoodt"
    roles:
    - "author"
    info:
      github: "rcannood"
      orcid: "0000-0003-3641-729X"
  - name: "Katrien Quintelier"
    roles:
    - "contributor"
    info:
      github: "KatrienQ"
  - name: "Sofie Van Gassen"
    roles:
    - "contributor"
    info:
      github: "SofieVG"
  keywords:
  - "single-cell"
  - "openproblems"
  - "benchmark"
  license: "MIT"
  organization: "openproblems-bio"
  links:
    repository: "https://github.com/openproblems-bio/task_cyto_batch_integration"
    docker_registry: "ghcr.io"
    issue_tracker: "https://github.com/openproblems-bio/task_cyto_batch_integration/issues"
