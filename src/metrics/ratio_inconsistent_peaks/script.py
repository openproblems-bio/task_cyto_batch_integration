import sys
from collections import defaultdict

import anndata as ad
import numpy as np

## VIASH START
# The following code has been auto-generated by Viash.
base_dir = "/Users/putri.g/Documents/cytobenchmark/debug"
filename = "lille_spectral_flow_cytometry.batchadjust_all_controls.batchadjust_all_controls.output.h5ad"
par = {
    "input_unintegrated": f"{base_dir}/input_unintegrated_1/unintegrated.h5ad",
    "input_integrated_split1": f"{base_dir}/input_integrated_split1_1/{filename}",
    "input_integrated_split2": f"{base_dir}/input_integrated_split2_1/{filename}",
    "output": "resources_test/task_cyto_batch_integration/ratio_inconsistent_peaks_score.h5ad",
}
meta = {
    "name": "ratio_inconsistent_peaks",
}

# for local testing only
# import src.metrics.ratio_inconsistent_peaks.helper as metric_helper
# from src.utils.helper_functions import (
#     get_obs_var_for_integrated,
#     remove_unlabelled,
#     subset_markers_tocorrect,
#     subset_nocontrols,
# )

## VIASH END

sys.path.append(meta["resources_dir"])

import helper as metric_helper

# from helper import call_peaks, get_kde_density
from helper_functions import (
    get_obs_var_for_integrated,
    remove_unlabelled,
    subset_markers_tocorrect,
    subset_nocontrols,
)

print("Reading input files", flush=True)
integrated_s1 = ad.read_h5ad(par["input_integrated_split1"])
integrated_s2 = ad.read_h5ad(par["input_integrated_split2"])
unintegrated = ad.read_h5ad(par["input_unintegrated"])

print("Formatting input files", flush=True)
integrated_s1, integrated_s2 = get_obs_var_for_integrated(
    integrated_s1, integrated_s2, unintegrated
)

integrated_s1 = subset_nocontrols(integrated_s1)
integrated_s1 = subset_markers_tocorrect(integrated_s1)
integrated_s1 = subset_nocontrols(integrated_s1)
integrated_s1 = remove_unlabelled(integrated_s1)

integrated_s2 = subset_nocontrols(integrated_s2)
integrated_s2 = subset_markers_tocorrect(integrated_s2)
integrated_s2 = subset_nocontrols(integrated_s2)
integrated_s2 = remove_unlabelled(integrated_s2)

donor_list = integrated_s1.obs["donor"].unique()

print("Compute metric (per cell type)", flush=True)

# case 1 = consistent peaks in unintegrated and also in integrated
# case 3 = consistent peaks in unintegrated but inconsistent in integrated
# not recording case 2 or 4 where unintegrated is inconsistent
n_case1 = 0
n_case3 = 0

# so we can see where each cases comes from
case_details = defaultdict(list)

for donor in donor_list:
    # for testing only
    # donor = donor_list[0]

    print("Processing donor", donor, flush=True)

    u_view = unintegrated[unintegrated.obs["donor"] == donor]

    # process per split
    s1_view = integrated_s1[integrated_s1.obs["donor"] == donor]
    s2_view = integrated_s2[integrated_s2.obs["donor"] == donor]

    celltype_list = s1_view.obs["cell_type"].unique()

    for celltype in celltype_list:
        # for testing only
        # celltype = celltype_list[0]

        print(f"Processing celltype {celltype}", flush=True)

        u_view_ct = u_view[u_view.obs["cell_type"] == celltype]
        s1_view_ct = s1_view[s1_view.obs["cell_type"] == celltype]
        s2_view_ct = s2_view[s2_view.obs["cell_type"] == celltype]

        if s1_view_ct.shape[0] < 100 or s2_view_ct.shape[0] < 100:
            print(f"Skipping celltype {celltype} and donor {donor}.", flush=True)
            if s1_view_ct.shape[0] < 100:
                print(
                    f"Because n_cells in s1 is {s1_view_ct.shape[0]}, less than 100",
                    flush=True,
                )
            else:
                print(
                    f"Because n_cells in s2 is {s2_view_ct.shape[0]}, less than 100",
                    flush=True,
                )
            # TODO uncomment me when done
            continue

        # unintegrated for split 1
        u_view_ct_s1 = u_view_ct[u_view_ct.obs["split"] == 1]
        u_view_ct_s2 = u_view_ct[u_view_ct.obs["split"] == 2]

        for marker in s1_view_ct.var.index:
            # for testing only
            # marker = u_view_ct.var.index[0]

            print(f"Processing marker {marker} for celltype {celltype}", flush=True)

            print("--------------------------------", flush=True)
            print("Computing peaks for unintegrated", flush=True)

            print("Standardising marker expression", flush=True)
            # standardise marker expression based on pooled mean and sd of
            # unscaled marker expression for unintegrated data for split 1 and 2
            u_s1_unscaled = np.array(u_view_ct_s1[:, marker].layers["preprocessed"])
            u_s2_unscaled = np.array(u_view_ct_s2[:, marker].layers["preprocessed"])

            u_s1_scaled, u_s2_scaled = metric_helper.standardise_marker_expression(
                u_s1_unscaled,
                u_s2_unscaled,
            )
            print("Computing KDE density", flush=True)
            density_dist_u_s1 = metric_helper.get_kde_density(
                expression_array=u_s1_scaled
            )
            density_dist_u_s2 = metric_helper.get_kde_density(
                expression_array=u_s2_scaled
            )

            print("Calling peaks", flush=True)

            peaks_u_s1 = metric_helper.call_peaks(density_dist_u_s1)
            peaks_u_s2 = metric_helper.call_peaks(density_dist_u_s2)

            print("--------------------------------", flush=True)

            print("\n", flush=True)

            print("--------------------------------", flush=True)
            print("Computing peaks for integrated", flush=True)

            print("Standardising marker expression", flush=True)
            # standardise marker expression based on pooled mean and sd of
            # unscaled marker expression for unintegrated data for split 1 and 2
            s1_unscaled = np.array(s1_view_ct[:, marker].layers["integrated"])
            s2_unscaled = np.array(s2_view_ct[:, marker].layers["integrated"])

            # if s1_unscaled or s2_unscaled is all zeros,
            # but the uncorrected version is not, this is a guaranteed
            # case 1 or 3 as corrected version is flat but the
            # uncorrected version is not.
            # we can detect this by calculating we can't calculate sd
            if not (np.std(s1_unscaled) == 0 and np.std(u_s1_unscaled) == 0) or (
                np.std(s2_unscaled) == 0 and np.std(u_s2_unscaled) == 0
            ):
                print(
                    f"WARNING: Marker {marker}, donor {donor}, cell type {celltype}: has no variance either before or after integration. Automatic to case 3.",
                    flush=True,
                )
                n_case3 += 1
                case_details["case3"].append((donor, celltype, marker))
                continue

            s1_scaled, s2_scaled = metric_helper.standardise_marker_expression(
                s1_unscaled,
                s2_unscaled,
            )
            print("Computing KDE density", flush=True)
            density_dist_s1 = metric_helper.get_kde_density(s1_scaled)
            density_dist_s2 = metric_helper.get_kde_density(s2_scaled)

            print("Calling peaks", flush=True)

            peaks_s1 = metric_helper.call_peaks(density_dist_s1)
            peaks_s2 = metric_helper.call_peaks(density_dist_s2)

            print("--------------------------------", flush=True)

            print("\n", flush=True)

            print(
                f"Comparing peaks between unintegrated and integrated for {donor}, {celltype}, {marker}",
                flush=True,
            )

            # case 1 or 3 where we have consistent peaks in unintegrated
            if peaks_u_s1 == peaks_u_s2:
                if peaks_s1 != peaks_s2:
                    n_case3 += 1
                    case_details["case3"].append((donor, celltype, marker))
                else:
                    n_case1 += 1
                    case_details["case1"].append((donor, celltype, marker))
            else:
                print(
                    "WARNING! Inconsistent peaks detected in unintegrated data (case 2 or 4). Skipping calculation",
                    flush=True,
                )
                print(
                    f"Number of peaks in unintegrated split 1: {peaks_u_s1}, split 2: {peaks_u_s2}",
                    flush=True,
                )
                case_details["case2or4"].append((donor, celltype, marker))

            print("Done comparing peaks.", flush=True)
            print("\n", flush=True)

print("Done processing all celltypes and donors", flush=True)
print("Calculating ratio", flush=True)

if n_case1 + n_case3 == 0:
    print(
        "Only case 2 or 4 are found!. Cannot calculate metric.",
        flush=True,
    )
    metric_val = np.nan
else:
    metric_val = n_case3 / (n_case1 + n_case3)


print("Write output AnnData to file", flush=True)
output = ad.AnnData(
    uns={
        "dataset_id": integrated_s1.uns["dataset_id"],
        "method_id": integrated_s1.uns["method_id"],
        "metric_ids": [meta["name"]],
        "metric_values": [metric_val],
        "n_cases": {
            "case1": n_case1,
            "case3": n_case3,
            "case2or4": len(case_details["case2or4"]),
        },
        "case_details": dict(case_details),
    }
)
output.write_h5ad(par["output"], compression="gzip")

# print(uns_metric_ids, uns_metric_values)
